\chapter{Marco  de referencia teórico}
\label{ch:marco}

El éxito en el diseño y la implementación de un sistema de control de acceso basado en reconocimiento facial depende, en gran medida, de la solidez conceptual que sustente cada decisión de ingeniería. Por ello, en este capítulo se presentan los conceptos fundamentales que guiarán el desarrollo del sistema. Se articulan las definiciones, los modelos y buenas prácticas necesarias para justificar la arquitectura propuesta, orientar la selección de tecnologías y sustentar los criterios de validación.

En consecuencia con la naturaleza multidisciplinaria del sistema, que combina \textit{hardware} especializado, algoritmos de inteligencia artificial y servicios distribuidos, el capítulo integra conceptos clave de diversas áreas, incluyendo:

\begin{enumerate}
    \item Sistemas embebidos
    \item Sistemas operativos embebidos y \textit{Yocto Project}
    \item Computación en la nube y su papel en arquitecturas IoT
    \item Herramientas de reconocimiento y detección facial
\end{enumerate}

La Figura \ref{fig:mapa_conceptual} ilustra los ejes temáticos que se desarrollarán en este capítulo, proporcionando una visión general de cómo se interrelacionan estos conceptos para formar la base teórica del sistema propuesto. La profundización en cada uno de estos ejes busca no solo contextualizar el trabajo, sino también establecer un marco de referencia que permita contrastar la implementación del proyecto con el estado del arte.

\clearpage

\begin{figure*}[h!]
    \centering
    \input{fig/tikz/mapa_conceptual.tex}
    \caption{Mapa conceptual de los ejes temáticos del sistema propuesto.}
    \label{fig:mapa_conceptual}
\end{figure*}

\section{Sistemas embebidos}
Un sistema embebido, como Wolf define en \cite{wolf_embedded_2012}, ``\textit{es un dispositivo que incorpora una computadora programable, pero que no está destinado a funcionar como una computadora de propósito general}''. Es un conjunto de componentes de hardware y software, y quizás componentes mecánicos, dedicados a realizar una función específica, o un conjunto acotado de funciones, dentro de un sistema mayor, y que generalmente opera con recursos limitados y bajo requisitos estrictos de confiabilidad y tiempo real \cite{barr_embedded_1999}.

Los sistemas embebidos son ubicuos en la vida cotidiana, y se encuentran en una amplia variedad de aplicaciones. Su diseño y aplicación son una necesidad fundamental para múltiples áreas de la ingeniería, pues dispositivos como automóviles, teléfonos móviles y electrodomésticos dependen en gran medida de microprocesadores embebidos. Para integrar estos componentes en un sistema, los departamentos de ingeniería deben ser capaces de identificar tareas computacionales específicas dentro del producto, diseñar una plataforma de hardware con capacidad de entrada/salida que permita ejecutar dichas tareas, e implementar el software que las coordine de forma eficiente \cite{wolf_embedded_2012}. 

El diseño de sistemas embebidos enfrenta desafíos significativos que van más allá de la mera funcionalidad. Según Jebril y Abu Al-Haija, los sistemas embebidos deben operar bajo restricciones físicas y temporales estrictas, lo que complica su diseño y verificación \cite{jebril_challenges_2017}. Entre los retos más relevantes destacan: la selección adecuada del hardware para cumplir simultáneamente con los requisitos de desempeño y las limitaciones presupuestarias; el cumplimiento estricto de plazos de respuesta en aplicaciones sensibles al tiempo; la minimización del consumo energético, especialmente en dispositivos alimentados por batería; y la necesidad de asegurar confiabilidad en entornos de operación continua o críticos \cite{wolf_embedded_2012}.  

Adicionalmente, se espera que muchos de estos sistemas sean escalables y actualizables, lo cual añade complejidad al diseño inicial. Estos retos, que no suelen presentarse en la misma magnitud en sistemas de propósito general, requieren un enfoque metodológico riguroso y una comprensión profunda de la interacción entre hardware, software y entorno de operación.

\subsection{Características principales}

Los rasgos distintivos de los sistemas embebidos comúnmente citados en la literatura consultada, se resumen en la siguiente tabla: 

\begin{longtable}{l|p{10cm}}
    \caption{Principales características de los sistemas embebidos} \label{tab:embedded_characteristics} \\
    \hline
    \multicolumn{1}{c|}{\textbf{Característica}} & \multicolumn{1}{c}{\textbf{Descripción}} \\
    \hline
    \endfirsthead
    
    \multicolumn{2}{c}{\tablename\ \thetable{}: Principales características de los sistemas embebidos (continuación)} \\
    \hline
    \multicolumn{1}{c|}{\textbf{Característica}} & \multicolumn{1}{c}{\textbf{Descripción}} \\
    \hline
    \endhead
    
    \hline
    \multicolumn{2}{r}{\textit{Continúa en la siguiente página}} \\
    \endfoot
    
    \hline
    \endlastfoot
    
    Restricción de recursos & CPU, memoria y energía limitadas obligan a optimizar código y hardware \cite{henriksson_2006}.\\
    \hline

    Propósito  específico & El software se diseña para una tarea concreta (p. ej., validar credenciales biométricas) \cite{wolf_embedded_2012}.\\
    \hline

    Operación en tiempo real & Se exige cumplir plazos máximos de respuesta (determinismo) \cite{shyamasundar_validating_2001}.\\
    \hline

    Alta confiabilidad & El dispositivo suele operar de forma autónoma y continua, por lo que los fallos son inaceptables \cite{windriver_embedded_security}.\\
    \hline

    Integración hardware-software & El diseño busca optimizar electrónica, sistema operativo y aplicación de manera conjunta \cite{wolf_embedded_2012}.\\
    \hline

    Interfaz con el entorno & Tienen la capacidad de interactuar con el entorno a través de unidades de entrada/salida e interfaces de comunicación. \cite{wolf_embedded_2012}.\\


\end{longtable}


\subsection{Clasificación de los sistemas embebidos según su nivel de complejidad}

Los sistemas embebidos pueden clasificarse según diversos criterios, siendo uno de los más relevantes el nivel de complejidad, el cual abarca tanto aspectos del hardware como del software, así como la interacción con el entorno físico. Respecto a esto, Lee y Seshia definen a los sistemas embebidos como ``\textit{computadoras menos visibles que interactúan con procesos físicos, típicamente en la forma de sistemas ciberfísicos con lazos de retroalimentación entre los procesos físicos y el software}'' \cite{lee_introduction_2017}. Esta interacción impone restricciones y retos específicos de diseño que varían según el tipo de sistema.

Según Wolf \cite{wolf_embedded_2012}, los sistemas embebidos pueden clasificarse en cuatro niveles de complejidad creciente: 
\begin{enumerate} 
    \item \textbf{Sistemas embebidos autónomos simples}, tales como relojes digitales o termostatos, los cuales ejecutan una lógica de control elemental y suelen operar sin conectividad o interacción compleja.
    \item \textbf{Sistemas de tiempo real}, los cuales requieren respuestas dentro de márgenes temporales estrictos. Estos sistemas son típicos en automóviles, dispositivos médicos y control industrial.
    \item \textbf{Sistemas embebidos con múltiples procesadores o coprocesadores}, que integran arquitecturas heterogéneas optimizadas para tareas específicas, como decodificadores multimedia o estaciones base de comunicación.
    \item \textbf{Sistemas embebidos distribuidos}, que incluyen componentes interconectados a través de redes, con alta complejidad de coordinación y sincronización, como los sistemas automotrices modernos y las infraestructuras inteligentes.
\end{enumerate}

Esta categorización puede también relacionarse con el grado de criticidad del sistema. Tal como señalan Lee y Seshia, ``\textit{los sistemas ciberfísicos enfrentan desafíos únicos, como la necesidad de garantizar propiedades temporales en un entorno concurrente, donde la precisión depende del comportamiento tanto computacional como físico}'' \cite{lee_introduction_2017}. Por tanto, mientras los sistemas simples pueden tolerar ciertos errores o retrasos, los sistemas complejos, como los sistemas embebidos distribuidos en la industria automotriz o cirugía robótica, requieren garantías formales sobre su comportamiento.

En resumen, el nivel de complejidad de un sistema embebido se encuentra determinado por factores como la criticidad temporal, la concurrencia, la heterogeneidad de hardware y la capacidad de integración en redes de sensores y actuadores. Esta clasificación no solo guía las decisiones de diseño, sino que también establece el enfoque metodológico a seguir en su desarrollo.

\subsection{Aplicación de los sistemas embebidos en control de acceso}
Los sistemas embebidos juegan un papel fundamental en los sistemas modernos de control de acceso, particularmente en aplicaciones donde se requiere una validación rápida, confiable y autónoma de la identidad del usuario. El uso de propósito específico, el bajo consumo energético y la capacidad de operar en tiempo real hacen que los sistemas embebidos sean ideales para este tipo de aplicaciones, donde se debe responder a eventos del entorno físico en un tiempo limitado.

En el estudio de Guerbaoui et al., se presenta una plataforma funcional basada en una Raspberry Pi 3 y una cámara Intel RealSense D415, utilizando clasificadores en cascada Haar para la detección y reconocimiento facial. Este sistema fue desarrollado específicamente para operar en tiempo real y en condiciones variables de iluminación y ángulos de visión, mostrando un desempeño adecuado para aplicaciones de vigilancia en instalaciones sensibles \cite{guerbaoui_2025}.

De manera complementaria, Kalkar et al. proponen una arquitectura distribuida en la que un sistema embebido realiza la detección de rostros a través de cámaras IP, y delega el reconocimiento facial a un servidor computacional. Se emplean modelos de detección como \textit{YOLO} y redes neuronales ligeras (\textit{MobileFaceNets}), lo que permite mantener un equilibrio entre velocidad y precisión. El diseño está orientado a aplicaciones en zonas restringidas como oficinas o centros educativos, donde se requiere monitoreo continuo con capacidad de respuesta en tiempo real \cite{kalkar_2020}.

Finalmente, Hammami y Alhammami desarrollan un sistema de control de acceso robusto que combina reconocimiento facial con códigos QR cifrados, ejecutado completamente sobre una Raspberry Pi 4. Esta solución, además de mejorar la precisión del reconocimiento, permite validar la identidad de visitantes mediante códigos de un solo uso y registra todos los eventos de acceso en una base de datos local, logrando un rendimiento de 8.27 FPS (cuadros por segundo) en condiciones reales de uso \cite{hammami_2024}.

Estos estudios evidencian que los sistemas embebidos son una opción viable y efectiva para implementar soluciones de control de acceso basadas en reconocimiento facial. La combinación de hardware especializado, algoritmos optimizados y la capacidad de operar en tiempo real permiten desarrollar sistemas que cumplen con los requisitos de seguridad y eficiencia necesarios en entornos críticos.

\section{Sistemas operativos embebidos y \textit{Yocto Project}}


Un sistema operativo embebido es un software especializado que proporciona servicios básicos como gestión de hardware, planificación de tareas y comunicación entre procesos, adaptados a las restricciones y necesidades particulares de un sistema embebido. Según Holt y Huang, estos sistemas están diseñados para ofrecer un conjunto mínimo pero suficiente de funciones orientadas a una aplicación específica, con alta eficiencia, bajo consumo de recursos y fiabilidad en tiempo real, permitiendo controlar periféricos y tareas críticas de forma predecible \cite{holt_2018_embedded_os}.

Wang complementa esta definición al señalar que un sistema operativo embebido no es un sistema monolítico, sino un conjunto modular de funciones esenciales que permiten la ejecución coordinada y determinista de múltiples tareas en ambientes con limitaciones físicas y temporales \cite{wang_2023_embedded_RTOS}. Estas características lo diferencian de los sistemas operativos de propósito general, cuya arquitectura y funcionalidad están pensadas para entornos flexibles y de uso amplio, como computadoras personales o servidores.

Con el aumento del poder de cómputo en las plataformas embebidas, Linux se ha convertido en una opción popular para este tipo de aplicaciones, gracias a su flexibilidad, código abierto y ecosistema maduro. Sin embargo, su uso requiere de adaptaciones importantes. Existen variantes como \textit{$\mu$Linux}, pensada para sistemas sin unidad de manejo de memoria (\textit{MMU}), y \textit{RTLinux}, que introduce una capa de emulación para manejar tareas críticas en tiempo real sobre el kernel de Linux estándar \cite{holt_2018_embedded_os} \cite{wang_2023_embedded_RTOS}.

Estas adaptaciones, aunque poderosas, implican un nivel de complejidad elevado en la construcción de un sistema embebido, pues es necesario personalizar diversos aspectos críticos del sistema operativo, como el gestor de arranque, la configuración del kernel, la gestión de memoria y la integración de controladores específicos para el hardware utilizado. En este contexto, herramientas como \textit{Yocto Project} cobran una especial relevancia. 

\subsection{Yocto Project: conceptos básicos y herramientas principales}

El \textit{Yocto Project} es un marco de trabajo de código abierto que permite crear distribuciones GNU/Linux adaptadas a sistemas embebidos mediante la generación reproducible de imágenes y paquetes binarios \cite{yocto_overview_2025}. Su piedra angular es el \textit{OpenEmbedded Build System}, cuyo motor de ejecución es \textit{BitBake}.  A grandes rasgos, los elementos fundamentales que es necesario comprender son los siguientes:

\begin{itemize}
    \item \textbf{BitBake}: herramienta de orquestación que interpreta \emph{meta‐datos} y ejecuta un grafo de tareas (\textit{parsing}, configuración, compilación, empaquetado, etc.) respetando dependencias y permitiendo compilación en paralelo \cite{bitbake_manual_2025}.  Conceptualmente, es similar a la herramienta \texttt{make} en \texttt{C}, pero está especializada en la construcción de stacks embebidos y en la gestión de cruces de arquitectura (\emph{cross‑compilation}).
      
    \item \textbf{Poky}: distribución de referencia que incluye BitBake; un conjunto mínimo de capas (\texttt{meta}, \texttt{meta‐poky}, \texttt{meta‐yocto‐bsp}, entre otras) y herramientas auxiliares.  Poky sirve de punto de partida para crear distribuciones personalizadas evitando partir de cero \cite{yocto_overview_2025}. Esta herramienta es especialmente útil para desarrolladores que buscan una solución rápida y funcional, ya que proporciona una base sólida sobre la cual construir.
    
    \item \textbf{Capas (\emph{layers})}: estructura modular donde se agrupan colecciones coherentes de meta‑datos.  Cada capa encapsula una política (p.\,ej.\ \textit{Board Support Package}\footnote{Un \textit{Board Support Package (BSP)} es un conjunto de controladores, bibliotecas y firmware específicos que permiten que un sistema operativo funcione en una plataforma de hardware particular. En el contexto de Yocto, un BSP incluye los componentes necesarios para adaptar Linux a un hardware específico como Raspberry Pi o BeagleBone.}, distro, aplicación) y puede activarse o desactivarse de forma independiente, lo que favorece la escalabilidad y el mantenimiento.  El modelo de capas fomenta la separación entre hardware (BSP), políticas de distribución y aplicaciones \cite{yocto_overview_2025}.
    
    \item \textbf{Meta-datos y \emph{recipes}}: los ficheros \verb|.bb| (\emph{recipes}) describen cómo obtener el código fuente, aplicar parches, compilar y empaquetar un componente.  Los ficheros \verb|.bbclass| (clases) encapsulan lógica común reutilizable, mientras que los \verb|.conf| establecen configuración global (máquina, distro, usuario).  Todo este conjunto constituye los \textit{meta-datos} que BitBake analiza para generar el grafo de tareas \cite{bitbake_manual_2025}.
    
    \item \textbf{Variables y sobrecargas}: la flexibilidad del sistema radica en la extensiva parametrización mediante variables (p.\,ej.\ \texttt{SRC\_URI}, \texttt{DEPENDS}) y en los mecanismos de sobrecarga (\texttt{override}) que permiten adaptar el comportamiento según máquina, arquitectura o política de distribución \cite{bitbake_manual_2025}.  
    \item \textbf{SDK y eSDK}: el flujo de trabajo típico culmina en una imagen para el dispositivo y en un SDK extensible que facilita el desarrollo de aplicaciones para el ambiente objetivo, manteniendo coherencia con la cadena de compilación empleada durante el proceso de construcción \cite{yocto_overview_2025}.  
  \end{itemize}

El uso de \textit{Yocto Project} permite a los desarrolladores crear distribuciones personalizadas de Linux para sistemas embebidos, optimizando el proceso de construcción y facilitando la integración de controladores y aplicaciones específicas. Esta flexibilidad es esencial para abordar los desafíos que presentan los sistemas embebidos, donde cada proyecto puede requerir un enfoque único en términos de hardware y software.

\subsection{Ventajas y desventajas de utilizar \textit{Yocto} para sistemas de propósito específico}
El uso de esta herramienta presenta beneficios, pero también desventajas que deben tomarse en cuenta para determinar su idoneidad en un proyecto específico. En la \textit{Tabla \ref{tab:yocto_pros_cons}} se contrastan los puntos más importantes encontrados en la literatura consultada \cite{streif_2016}, \cite{abbott_2018}, \cite{pera_2022}, \cite{karacali_2024}.


\begin{longtable}{p{7.5cm}|p{7.5cm}}
    \caption{Ventajas y desventajas del uso de \textit{Yocto} en sistemas embebidos} \label{tab:yocto_pros_cons} \\
    \hline
    \multicolumn{1}{c|}{\textbf{Ventajas}} & \multicolumn{1}{c}{\textbf{Desventajas}} \\
    \hline
    \endfirsthead
    
    \multicolumn{2}{c}{\tablename\ \thetable{}: Ventajas y desventajas del uso de \textit{Yocto} en sistemas embebidos (continuación)} \\
    \hline
    \multicolumn{1}{c|}{\textbf{Ventajas}} & \multicolumn{1}{c}{\textbf{Desventajas}} \\
    \hline
    \endhead
    
    \hline
    \multicolumn{2}{r}{\textit{Continúa en la siguiente página}} \\
    \endfoot
    
    \hline
    \endlastfoot
    
    Flexibilidad y personalización granular mediante el concepto de \textit{layers} y \textit{recipes}, que permite generar distribuciones altamente adaptadas al hardware y a los requisitos de la aplicación & Curva de aprendizaje pronunciada: la complejidad de los metadatos y la multitud de variables/sobrecargas de BitBake exige experiencia avanzada \\ 
    \hline
    
    Reproducibilidad y trazabilidad del proceso de construcción gracias a BitBake y los mecanismos de \texttt{sstate‑cache}, lo que facilita auditorías y cumplimiento normativo. & Tiempos de compilación prolongados y elevado consumo de recursos (CPU, RAM, almacenamiento) en la primera construcción completa. \\
    \hline

    Soporte multiarquitectura y ecosistema industrial con BSPs mantenidos por la comunidad y por proveedores comerciales (Wind River, Intel, etc.) y versiones LTS. & Sobrecoste para prototipado rápido: en proyectos de ciclo de vida corto, herramientas más ligeras (p. ej. \textit{Buildroot}) pueden resultar más ágiles.\\
    \hline

    Generación automática de SDKs coherentes con la imagen de tiempo de ejecución, lo que simplifica la integración continua y el desarrollo de aplicaciones de usuario. & Depuración compleja de recetas y dependencias: los fallos pueden propagarse a través de múltiples capas, dificultando la localización del origen.\\
    \hline

    Escalabilidad y mantenibilidad de proyectos de gran tamaño gracias al paradigma de capas, que favorece la modularidad y el versionado independiente de componentes. & Documentación extensa, pero dispersa: la rápida evolución de capas externas puede provocar incompatibilidades y fallos de descarga (\textit{fetch errors}).
\end{longtable}

En síntesis, aunque \textit{Yocto Project} constituye una alternativa de gran solidez y flexibilidad, capaz de orquestar dependencias complejas y sostener proyectos de gran escala, esa misma robustez conlleva una curva de aprendizaje pronunciada y procesos de compilación más extensos, lo que puede elevar los costos de adopción y mantenimiento. Ahora bien, para desarrollos de menor envergadura o prototipos que requieren iteraciones rápidas, es importante destacar que existen otras herramientas más livianas como \textit{Buildroot} que resultan ventajosas, ya que su simplicidad reduce la barrera de entrada y acelera la generación de imágenes, favoreciendo tiempos de desarrollo significativamente más cortos, como se señala en \cite{pera_2022}.

\section{Internet de las Cosas y computación en la nube para sistemas embebidos}
\label{sec:iot_cloud}
La implementación de sistemas de control de acceso basados en reconocimiento facial se posiciona en un contexto donde es necesario integrar múltiples tecnologías y paradigmas. En este sentido, se puede articular el sistema propuesto en torno a tres ejes tecnológicos, como lo son el Internet de las Cosas (IoT), la computación en la nube y el procesamiento de datos biométricos. En esta sección se describen los conceptos fundamentales de los dos primeros ejes, y cómo se interrelacionan para formar sistemas distribuidos. Posteriormente, en la siguiente sección se abordará el tema del procesamiento de datos biométricos en el contexto de técnicas y herramientas de reconocimiento y detección facial.

\subsection{Internet de las Cosas en los sistemas embebidos}
Según Nimodiya y Ajankar, ``\textit{el Internet de las Cosas es simplemente una interacción entre el mundo físico y el mundo digital, y constituye una red de objetos físicos o personas llamadas ``cosas'' que están embebidas con software, electrónica, sensores y conectividad de red para recopilar y compartir datos}'' \cite{nimodiya_2022_IoTreview}. Por su parte, Dauda et al. resaltan que el paradigma IoT se ha convertido en un habilitador esencial de la innovación en numerosos ámbitos de la actividad humana, incluidos la manufactura, la agricultura, la salud, la educación, la seguridad y el transporte \cite{dauda_survey_2024}. 

En el sector manufacturero, por ejemplo, sensores y actuadores conectados permiten supervisar el rendimiento de los equipos, rastrear inventarios en tiempo real, optimizar las cadenas de suministro y habilitar el mantenimiento predictivo, lo que reduce al mínimo los tiempos de inactividad, incrementa la eficiencia productiva y disminuye los costos operativos \cite{dauda_survey_2024}.

Según una publicación de Statista, se prevé que el número de dispositivos IoT conectados duplicará los 15,9 mil millones de dispositivos en 2023, alcanzando los más de 32,1 mil millones en 2030 \cite{vailshery_iot_devices_2023}. Esta tendencia resalta el papel fundamental de la conectividad y la interoperabilidad entre dispositivos, lo que permite crear sistemas inteligentes y distribuidos, que son los que dominan el mercado actual.

De acuerdo con Nimodiya y Ajankar, la literatura converge en un conjunto de rasgos que definen la esencia operativa, tecnológica y social del IoT. En la \textit{Tabla \ref{tab:iot_characteristics}} se resumen las características citadas en \cite{nimodiya_2022_IoTreview}.


\begin{longtable}{l|p{10cm}}
    \caption{Principales características del paradigma IoT} \label{tab:iot_characteristics} \\
    \hline
    \multicolumn{1}{c|}{\textbf{Característica}} & \multicolumn{1}{c}{\textbf{Descripción}} \\
    \hline
    \endfirsthead
    
    \multicolumn{2}{c}{\tablename\ \thetable{}: Principales características del paradigma IoT (continuación)} \\
    \hline
    \multicolumn{1}{c|}{\textbf{Característica}} & \multicolumn{1}{c}{\textbf{Descripción}} \\
    \hline
    \endhead
    
    \hline
    \multicolumn{2}{r}{\textit{Continúa en la siguiente página}} \\
    \endfoot
    
    \hline
    \endlastfoot
    
    Inteligencia & Integración de algoritmos y cómputo embebido que dota a los dispositivos de capacidad para percibir su contexto, razonar y actuar de forma autónoma, habilitando la llamada \textit{inteligencia de ambiente}.\\
    \hline

    Conectividad & Habilita la accesibilidad a redes y la compatibilidad entre dispositivos heterogéneos, reforzando el valor de la información conforme al principio de la \textit{Ley de Metcalfe} \footnote{La \textit{Ley de Metcalfe} establece que el valor de una red es proporcional al cuadrado del número de usuarios conectados.}. \\
    \hline

    Naturaleza dinámica & Los nodos cambian de estado (activo, inactivo, conectado, desconectado) y de contexto (p. ej., posición, velocidad, temperatura), generando datos en tiempo real que requieren gestión continua.\\
    \hline

    Escala masiva & El número de dispositivos que deben ser gestionados y conectados entre sí, supera con creces al número de conexiones en la Internet tradicional, multiplicando los retos de direccionamiento, almacenamiento y procesamiento eficiente de grandes volúmenes de datos.\\
    \hline

    Sensado & Uso extensivo de sensores que capturan variables del entorno físico, posibilitando la creación de representaciones digitales y actualizadas del mundo real. \\
    \hline

    Heterogeneidad & Coexistencia de plataformas de hardware, protocolos de comunicación y modelos de datos diversos; el diseño de soluciones IoT debe garantizar interoperabilidad, extensibilidad y modularidad.\\
    \hline

    Seguridad & Los dispositivos y los datos están expuestos a un amplio espectro de amenazas; la protección de los servicios, redes y procesos exige arquitecturas de confianza, cifrado y gestión de la privacidad.\\
    \hline


\end{longtable}

Estos atributos hacen que el IoT se haya convertido en un habilitador transversal de la innovación; su conectividad, capacidad de sensado y procesamiento de datos permiten la creación de sistemas inteligentes y distribuidos cuyas posibles aplicaciones son prácticamente ilimitadas. Esta variedad en su aplicabilidad, ha dado lugar a un ecosistema diverso de tecnologías, protocolos y arquitecturas, que van desde dispositivos de bajo consumo y bajo costo hasta sistemas complejos de análisis de datos en tiempo real.

La literatura reciente señala que los sistemas IoT pueden clasificarse, a grandes rasgos, en tres estilos arquitectónicos complementarios: \textit{on-cloud} (en la nube), \textit{on-edge} (en el borde) y \textit{fog} (de niebla). Cada uno de estos estilos aborda diferentes aspectos del procesamiento y almacenamiento de datos, y su elección depende de los requisitos específicos de la aplicación, respondiendo a compromisos entre latencia, escalabilidad y consumo de recursos.

\begin{itemize}
    \item \textbf{Arquitectura \textit{on‑cloud}.} Todo el flujo de datos se encamina a plataformas en la nube con capacidad prácticamente ilimitada de cómputo y almacenamiento. Este modelo facilita la orquestación y el mantenimiento centralizados, así como la explotación de servicios avanzados (analítica masiva, \textit{machine learning as‑a‑service}, etc.), a costa de una mayor dependencia de la conectividad de red y de un retardo apreciable en aplicaciones sensibles al tiempo \cite{dauda_survey_2024}.
    
    \item \textbf{Arquitectura \textit{on‑edge}.}  El procesamiento se traslada a los dispositivos periféricos o a unidades locales con el fin de acercar la computación a la fuente de los datos.  Con ello se reduce la congestión debido a la red, se atenúa la latencia y se alivian problemas de privacidad, ya que, de ser necesario únicamente se envían a la nube datos filtrados o agregados.  Al mismo tiempo, el software debe enfrentarse a desafíos como la heterogeneidad y a las limitaciones de capacidad de cómputo de los nodos del borde \cite{dauda_survey_2024}.  
    
    \item \textbf{Arquitectura \textit{fog}.}  Actúa como un nivel intermedio y distribuido que combina la capacidad de integración global propia de la nube con la inmediatez del borde.  Los nodos \textit{fog} se ubican en la red de acceso y ofrecen servicios de cómputo, almacenamiento temporal y control de seguridad próximos al lugar donde se generan los eventos, al tiempo que mantienen sincronización con la nube para tareas de larga duración o con requisitos intensivos de recursos \cite{sethi_iot_2017}.  

\end{itemize}

Este abanico de estilos no debe entenderse como excluyente, sino como un complemento sobre el que el sistema complejo distribuye su lógica según sus restricciones concretas de latencia, ancho de banda, autonomía energética o confidencialidad de los datos. Ahora bien, en el caso de que el sistema requiera de un procesamiento intensivo de datos, como es el caso del reconocimiento facial, las arquitecturas de tipo \textit{on-cloud} y \textit{fog} se presentan como opciones atractivas debido a su capacidad para manejar grandes volúmenes de datos y realizar análisis complejos. En ambos casos, la computación en la nube se convierte en un componente esencial del sistema.

\subsection{Computación en la nube y su papel en arquitecturas IoT}

La computación en la nube se define, de acuerdo con la National Institute of Standards and Technology (NIST), como ``\textit{un modelo para permitir el acceso ubicuo, conveniente y bajo demanda a un conjunto compartido de recursos informáticos configurables (p. ej., redes, servidores, almacenamiento, aplicaciones y servicios) que pueden ser aprovisionados y liberados rápidamente con un esfuerzo mínimo de gestión o interacción del proveedor}'' \cite{nist_2011}. 

Se establecen cinco características esenciales (autoservicio bajo demanda, amplio acceso a la red, agrupación de recursos, elasticidad rápida y servicio medido), tres modelos de servicio (IaaS, PaaS, SaaS) y cuatro modelos de despliegue (nube pública, privada, comunitaria e híbrida), sentando las bases conceptuales que distinguen a la nube frente a enfoques tradicionales ``\textit{on-premises}'' o locales \cite{nist_2011}.

La migración desde centros de datos locales hacia la nube se explica, en gran medida, por los beneficios de elasticidad y factura por uso, descritos tempranamente por Armbrust et al. \cite{armbrust_2010} y reforzados por prácticas recomendadas en marcos industriales como el \textit{AWS Well-Architected Framework - IoT Lens} \cite{aws_2024}. En esta evolución, los servicios de infraestructura (IaaS) abstraen hardware y redes, las plataformas (PaaS) ofrecen entornos gestionados para desplegar aplicaciones sin lidiar con sistemas operativos subyacentes, y el software como servicio (SaaS) entrega soluciones completas listas para el usuario final. El resultado es un espectro de opciones que permiten a los sistemas IoT, delegar cargas intensivas de cómputo a la nube, aprovechar economías de escala y acortar el ``\textit{time-to-market}'' o tiempo de comercialización mediante el consumo de servicios gestionados.

Para ejemplificar el papel de la computación en la nube en arquitecturas IoT, se puede considerar el trabajo de Thilakarathne et al. \cite{thilakarathne_2023}, que presenta una plataforma de gestión de cultivos para un invernadero de tomates que combina dos microcontroladores (NodeMCU y Arduino UNO) con una red de sensores ambientales y de suelo.  Los datos se envían mediante \textit{Wi-Fi} a la nube pública de \textit{Thinger.io}, donde se almacenan en \textit{buckets}, se visualizan en diagramas de seguimiento y se habilita el control remoto de actuadores (bombas peristálticas e iluminación).

Esta arquitectura \textit{edge–cloud} ilustra la transición desde soluciones puramente locales a modelos PaaS/SaaS: el borde (microcontroladores) capta y pre-procesa la información, mientras que la nube ofrece capacidad elástica de cómputo, persistencia y difusión en tiempo real, simplificando la analítica y la automatización de decisiones agrícolas.

Por su parte, Permana et al., describen en \cite{permana_2024} un sistema inteligente de control de acceso basado en cerraduras electrónicas gestionadas por un ESP32 que integra sensor de huellas y teclado.  El dispositivo registra eventos y recibe comandos a través de \textit{Firebase Realtime Database}, un servicio de \textit{Backend-as-a-Service} que abstrae la infraestructura subyacente.

Gracias a la computación en la nube, el sistema logra sincronización inmediata entre la cerradura y la aplicación Android del usuario, mantiene históricos de actividad y aplica principios de \textit{Zero Trust} al delegar la autenticación y la autorización en servicios gestionados.  Este caso evidencia cómo la computación en la nube potencia a la IoT en escenarios de seguridad física, al proporcionar escalabilidad, baja latencia de notificación y alta disponibilidad sin necesidad de servidores locales.

En síntesis, la incorporación de la computación en la nube en arquitecturas IoT aporta elasticidad para escalar el procesamiento según la variabilidad de la carga, alta disponibilidad gracias a infraestructuras redundantes distribuidas globalmente, y un modelo pago por uso que traslada el gasto de capital a gasto operativo.

Además, los servicios gestionados, como PaaS o BaaS, reducen la complejidad de mantener servidores propios, facilitan la integración de \textit{dashboards} y analítica avanzada, acelerando la iteración de prototipos y el tiempo de comercialización.  En conjunto, estas ventajas permiten a los equipos de desarrollo concentrarse en la lógica de dominio mientras delegan la gestión de la infraestructura a proveedores de nube consolidados.

No obstante, persisten retos significativos como: la latencia y la dependencia de conectividad que pueden comprometer funciones críticas en entornos con redes inestables \cite{andriulo_2024}; la protección de datos sensibles y el cumplimiento regulatorio exigen políticas de cifrado extremo a extremo, segmentación y \textit{Zero Trust} \cite{zanasi_2024}. Además, el riesgo de \textit{vendor lock-in}\footnote{El riesgo de \textit{vendor lock-in} se refiere a la dificultad de cambiar de proveedor de servicios en la nube debido a problemas como la dependencia de tecnologías muy específicas o incapacidad para migrar datos.} limita la portabilidad de las soluciones \cite{alhosban_2024}; y la naturaleza variable e impredecible de la facturación en la nube introduce incertidumbre presupuestaria \cite{deochake_2024}.

Paralelamente, la sostenibilidad energética de grandes centros de datos y el dimensionamiento correcto entre lógica en el borde y en la nube continúan siendo áreas activas de investigación.  Estos desafíos impulsan el interés por arquitecturas híbridas \emph{edge/fog-cloud} y mecanismos estandarizados de interoperabilidad que mitiguen las limitaciones sin renunciar a los beneficios del paradigma de la computación en la nube \cite{shehabi_2024}, \cite{fernando_2025}.

\section{Herramientas de reconocimiento y detección facial}

El procesamiento y análisis automatizado de datos biométricos es un aspecto fundamental en el desarrollo de sistemas de control de acceso. Particularmente, los sistemas que utilizan la verificación de identidad por medio de aspectos faciales, suelen dividir el proceso en dos etapas: la detección de rostros y el reconocimiento facial. El propósito de esta sección es presentar una visión general de estas dos etapas, así como de las herramientas y técnicas más relevantes en el ámbito del reconocimiento facial.

La detección facial se define como el procedimiento que, a partir de una imagen fija o un flujo de vídeo, localiza las regiones que contienen rostros humanos y las aísla del fondo y de otros objetos presentes en la escena, entregando como resultado la posición espacial del rostro mediante un recuadro o una máscara \cite{li_jain_2011}. Por su parte, el reconocimiento facial comprende el análisis del rostro previamente detectado para extraer un conjunto de características discriminantes (vector de rasgos) y compararlas con plantillas almacenadas en una base de datos, con el fin de verificar si corresponde a una identidad conocida o determinar la identidad más probable de la persona \cite{li_jain_2011}.

\subsection{Algoritmos y modelos populares de detección facial}

En las últimas dos décadas la detección automática de rostros ha evolucionado desde técnicas basadas en descriptores manuales hasta detectores profundos de una sola etapa. Algunas de las soluciones de mayor adopción académica e industrial son las siguientes:

\begin{itemize}
  \item \textbf{Viola--Jones / Haar Cascade}.  
        Pionero en la detección en tiempo real mediante \emph{features} Haar y un clasificador \emph{AdaBoost} en cascada \cite{viola_jones_2001}.

  \item \textbf{HOG + SVM (dlib)}.  
        Emplea histogramas de gradientes orientados (HOG) y un clasificador lineal SVM; mantiene buena precisión con bajo coste computacional \cite{dalal_triggs_2005}.

  \item \textbf{MTCNN}.  
        Red convolucional en cascada que combina detección y alineamiento facial en un mismo flujo multi-tarea \cite{zhang_mtcnn_2016}.

  \item \textbf{S$^3$FD}.  
        Detector de una sola pasada (\emph{single-shot}) diseñado para ser invariante a la escala, especialmente robusto para rostros pequeños \cite{zhang_s3fd_2017}.

  \item \textbf{BlazeFace}.  
        Arquitectura ligera optimizada para GPU móviles, capaz de superar las 200 FPS en dispositivos de gama alta \cite{bazarevsky_blazeface_2019}.

  \item \textbf{Familia YOLO (p.\,ej.\ YOLOv5-Face)}.  
        Detectores de una sola pasada que combinan alta velocidad y buena exactitud; versiones afinadas para rostros añaden anclas y pérdidas específicas \cite{redmon_yolo_2016}.

  \item \textbf{YuNet}.  
        Detector ultraligero ($\sim$76 mil parámetros) diseñado para dispositivos \emph{edge}; alcanza 81 \% \textit{mAP} \footnote{El \textit{mAP} es el promedio de precisión (\textit{mean Average Precision}) utilizado para evaluar la precisión de los modelos de detección de objetos.} en el \textit{benchmark} WIDER FACE con una latencia de apenas 1.6 ms por imagen \cite{wu_yunet_2023}.

\end{itemize}

Los enfoques clásicos de detección facial se basan en la extración explícita de características (\textit{features}) ``hechas a mano'', tales como los descriptores Haar combinados con \textit{AdaBoost} \cite{viola_jones_2001} o histogramas de gradientes orientados  \cite{dalal_triggs_2005}. Estos métodos utilizan un proceso en el que los investigadores definen manualmente el conjunto de descriptores matemáticos que capturan rasgos visuales considerados relevantes, tales como bordes, texturas, contrastes de intensidad, o formas geométricas, antes de entrenar el clasificador. Una vez extraídas estas características, fijas y de dimensión limitada, se alimentan clasificadores ligeros, como \textit{AdaBoost} o SVM, que permiten detectar rostros en imágenes.

Estos métodos, por lo general, ofrecen una ejecución muy ligera sobre CPU al no requerir operaciones convolucionales profundas. Sin embargo, su desempeño se degrada en presencia de variaciones de iluminación, obstrucciones parciales y poses fuera del plano, y suelen mostrar menores valores de precisión (mAP) en bases de datos desafiantes frente a los detectores modernos.

En contraste, los detectores basados en aprendizaje profundo emplean redes neuronales convolucionales entrenadas de extremo a extremo y se dividen según su arquitectura, en esquemas de dos etapas (p. ej., MTCNN) y de una sola etapa (p. ej., YOLO, S$^3$FD). Estos modelos aprenden representaciones jerárquicas de características y exhiben un rendimiento superior ante variaciones de escala, rotación y obstrucciones, aunque requieren de un mayor consumo de recursos computacionales y, en muchos casos, demanda de aceleradores GPU o VPU para lograr latencias aceptables en tiempo real \cite{zhang_mtcnn_2016}, \cite{bazarevsky_blazeface_2019}, \cite{redmon_yolo_2016}.

Ahora bien, la tendencia hacia arquitecturas ligeras y eficientes ha llevado al desarrollo de modelos como \textit{YuNet}, que equilibra minuciosamente exactitud y eficiencia, permitiendo su uso en dispositivos de bajo consumo energético. Este modelo prescinde del uso de anclas, que son comunes en los detectores de una sola etapa, y emplea una arquitectura totalmente basada en convoluciones separables en profundidad, complementada con un \textit{Tiny FPN} simplificado. Esto se traduce en únicamente 75 856 parámetros ($\sim$300 kB) y 149 MFLOPs para una entrada de $320 \times 320$ píxeles, cifras que lo situan por debajo de la quinta parte del tamaño de otros detectores ligeros \cite{wu_yunet_2023}.

A pesar de su diseño compacto, el modelo YuNet alcanza un rendimiento competitivo, logrando 81.1 \% de mAP en el set de alta dificultad de WIDER FACE \footnote{WIDER FACE es un conjunto de datos de referencia para detección facial que agrupa más de 32 000 imágenes con casi 400 000 rostros anotados en condiciones extremadamente variadas de escala, pose, iluminación y oclusión, lo que lo convierte en el estándar más exigente para evaluar la robustez de los detectores modernos \cite{yang_widerface_2016}.} y registra una latencia media de 1,6 ms por imagen en CPU \textit{Intel i7-12700K}, lo que habilita velocidades superiores a 600 FPS en resoluciones habituales y elimina la necesidad de aceleradores GPU externos \cite{wu_yunet_2023}.

En la \textit{Tabla \ref{tab:yunet_comparison}} se comparan las principales características de YuNet con otros detectores ligeros populares, como RetinaFace-0.25 y YOLO5-Face-n. En la tabla se subrayan los valores con mejor rendimiento en cada columna. Los modelos \textit{YuNet-s}, \textit{RetinaFace} y \textit{SCRFD-10g} se incluyen en la lista como referencia pero no se consideran para la comparación, ya que el primero es una versión reducida de YuNet y los otros dos son detectores de alta complejidad que por su tamaño y latencia no son adecuados para sistemas embebidos.

\begin{scriptsize}
    
    \begin{longtable}{c|l|r|r|c|c|c|c}
        \caption{Comparación de YuNet con otros detectores faciales (adaptado de \cite{wu_yunet_2023})}
        \label{tab:yunet_comparison} \\
        \hline
        \multicolumn{1}{c|}{\textbf{Tamaño}} &
        \multicolumn{1}{c|}{\textbf{Método}} &
        \multicolumn{1}{c|}{\textbf{Num. Parámetros}} &
        \multicolumn{1}{c|}{\textbf{FLOPs}} &
        \multicolumn{1}{c|}{\textbf{AP$_{easy}$}} &
        \multicolumn{1}{c|}{\textbf{AP$_{med}$}} &
        \multicolumn{1}{c|}{\textbf{AP$_{hard}$}} &
        \multicolumn{1}{c}{\textbf{Latencia}}\\
        \multicolumn{1}{c|}{\textbf{imagen}} &
        & \multicolumn{1}{c|}{(proporción)} &
        \multicolumn{1}{c|}{(M)} &
        & & & \multicolumn{1}{c}{(ms)}\\
        \hline
        \endfirsthead
        
        \multicolumn{8}{c}{\tablename\ \thetable{}: Comparación de YuNet con otros detectores faciales (continuación)}\\
    \hline
    \multicolumn{1}{c|}{\textbf{Tamaño}} &
    \multicolumn{1}{c|}{\textbf{Método}} &
    \multicolumn{1}{c|}{\textbf{Num. Parámetros}} &
    \multicolumn{1}{c|}{\textbf{FLOPs}} &
    \multicolumn{1}{c|}{\textbf{AP$_{easy}$}} &
    \multicolumn{1}{c|}{\textbf{AP$_{med}$}} &
    \multicolumn{1}{c|}{\textbf{AP$_{hard}$}} &
    \multicolumn{1}{c}{\textbf{Latencia}}\\
    \multicolumn{1}{c|}{\textbf{imagen}} &
    & \multicolumn{1}{c|}{(proporción)} &
    \multicolumn{1}{c|}{(M)} &
    & & & \multicolumn{1}{c}{(ms)}\\
    \hline
    \endhead
    
    \hline
    \multicolumn{8}{r}{\textit{Continúa en la siguiente página}}\\
    \endfoot
    
    \hline
    \endlastfoot
    
    %------------ 320 × 320 ----------------
    320$\times$320 & SCRFD-0.5g & 631\,410 (8.32×) & 195 & 0.850 & 0.754 & 0.372 & 3.4\\
    & RetinaFace-0.25 & 426\,608 (5.62×) & 245 & 0.765 & 0.611 & 0.271 & 4.2\\
    & YOLO5Face-n & 446\,376 (5.88×) & 185 & \underline{0.858} & \underline{0.793} & \underline{0.445} & 7.2\\
    & YuNet & \textbf{75\,856 (1.00×)} & \underline{149} & 0.836 & 0.747 & 0.395 & \underline{2.2}\\
    & YuNet-s & 54\,608 (0.72×) & 96 & 0.785 & 0.668 & 0.309 & 1.9\\
    & RetinaFace & 27\,293\,600 (359.81×) & 11\,070 & 0.868 & 0.742 & 0.341 & 49.1\\
    & SCRFD-10g & 4\,229\,905 (55.76×) & 3\,359 & 0.923 & 0.862 & 0.504 & 17.3\\
    \hline
    %------------ 640 × 640 ----------------
    640$\times$640 & SCRFD-0.5g & -- & 779 & \underline{0.907} & \underline{0.882} & 0.684 & 17.8\\
    & RetinaFace-0.25 & -- & 981 & 0.893 & 0.831 & 0.541 & 22.0\\
    & YOLO5Face-n & -- & 741 & \underline{0.907} & 0.880 & \underline{0.734} & 20.1\\
    & YuNet & -- & \underline{595} & 0.899 & 0.869 & 0.691 & \underline{11.3}\\
    & YuNet-s & -- & 386 & 0.876 & 0.834 & 0.591 & 8.7\\
    & RetinaFace & -- & 44\,260 & 0.943 & 0.908 & 0.659 & 232.7\\
    & SCRFD-10g & -- & 13\,435 & 0.949 & 0.935 & 0.814 & 95.0\\
    \hline
    %------------ Tamaño original ---------
    Tamaño orig. & SCRFD-0.5g & -- & -- & 0.892 & \underline{0.885} & \underline{0.820} & 25.0\\
    & RetinaFace-0.25 & -- & -- & \underline{0.907} & 0.883 & 0.742 & 57.0\\
    & YuNet & -- & -- & 0.892 & 0.883 & 0.811 & \underline{16.3}\\
    & YuNet-s & -- & -- & 0.887 & 0.871 & 0.768 & 13.8\\
    & RetinaFace & -- & -- & 0.955 & 0.941 & 0.847 & 463.7\\
    & SCRFD-10g & -- & -- & 0.923 & 0.925 & 0.885 & 137.8\\
    
\end{longtable}
\end{scriptsize}


La tabla anterior permite observar que YuNet, a pesar de su reducida cantidad de parámetros, en los 3 casos logra el mejor rendimiento en términos de latencia, por encima de otros detectores ligeros que son 5 veces más grandes. Esto tiene relación con su rendimiento en términos de FLOPs, que también tiene los registros más bajos entre los detectores comparados, lo que se traduce en una menor carga computacional y, por ende, una mayor velocidad de procesamiento.

Además, YuNet alcanza un rendimiento competitivo en términos de precisión (AP), con valores muy cercanos a los del resto de detectores, y en algunos casos incluso superándolos, como en la métrica AP$_{medium}$ para el caso de imágenes de 320$\times$320 píxeles, en el que YuNet supera RetinaFace a pésar de que este es 359 veces más grande en términos de número de parámetros.

Por otro lado, desde la óptica de la integración, el modelo se distribuye en formato ONNX y ha sido incorporado en la librería de modelos de OpenCV \footnote{OpenCV es una biblioteca de visión por computadora de código abierto que tiene una amplia gama de herramientas y algoritmos para el procesamiento de imágenes y videos.}, de modo que puede invocarse con una pocas líneas de código en C++ o Python, lo que facilita su adopción en proyectos de sistemas embebidos. Su bajo consumo de memoria, junto con la política de entrenamiento a partir de una única escala de entrada y el uso de asignación \textit{simOTA}, simplifica el ajuste de hiperparámetros y facilita su despliegue en dispositivos con recursos limitados \cite{wu_yunet_2023}.

\subsection{Servicios en la nube para reconocimiento facial}

A pesar de los avances en eficiencia y precisión de los algoritmos de detección y reconocimiento facial para dispositivos embebidos, estos sistemas enfrentan limitaciones inherentes de procesamiento, almacenamiento y consumo energético. Como solución a estas restricciones, los servicios de reconocimiento facial en la nube permiten delegar tareas computacionalmente intensivas a infraestructuras remotas, garantizando mayor escalabilidad, mantenimiento simplificado y actualizaciones constantes, como ya fue discutido en la sección \ref{sec:iot_cloud}. En la presente sección, se presenta una revisión de los principales servicios gestionados en la nube que ofrecen capacidades de reconocimiento facial, y que pueden integrarse con plataformas embebidas.

\begin{itemize}
  \item \textbf{Amazon Rekognition (AWS).} Servicio totalmente administrado (el proveedor se encarga de gestionar la configuración, mantenimiento, escalabilidad, actualizaciones y seguridad de la infraestructura subyacente) que detecta y analiza rostros en imágenes y video. Provee comparación uno-a-uno y uno-a-muchos, métricas de atributos (edad aparente, emociones, uso de gafas, etc.) y flujos de moderación de contenido. Se integra con otros servicios AWS (S3, Lambda, Kinesis) y ofrece precios por volumen de llamadas y por segundo de video procesado \cite{aws_rek}.
  
  \item \textbf{Azure Face API (Microsoft).} Incluye algoritmos para detección de rostros, verificación de identidad, agrupamiento y búsqueda en grandes colecciones. Soporta atributos faciales avanzados (pose, expresión, barba, accesorios) y perfiles de seguridad con Azure Active Directory. Dispone de niveles gratuitos y de pago por transacción, así como contenedores locales para escenarios \textit{edge} \cite{azure_face}.
  
  \item \textbf{Clarifai Face Recognition.} Plataforma basada en aprendizaje profundo que expone modelos pre-entrenados y personalizables para detección, verificación y búsqueda de rostros. Brinda SDKs en varios lenguajes, endpoints REST y gRPC, así como despliegue \emph{on-premise} (local) para requisitos de privacidad estrictos. Se factura bajo un modelo de pago por uso con niveles gratuitos y escalado automático \cite{clarifai_face}.
  
  \item \textbf{Face++ (Megvii).} Plataforma china con API REST y SDKs móviles que ofrece detección, verificación, búsqueda y análisis demográfico. Opera bajo un modelo de créditos pre-pago y cuenta con planes empresariales personalizados \cite{facepp}.

\end{itemize}

En la literatura se han documentado casos de uso exitosos de soluciones de reconocimiento facial en arquitecturas \textit{edge-cloud}, que ilustran el potencial de estas herramientas, principalmente la de Amazon Rekognition, para ampliar las capacidades de sistemas empotrados con recursos limitados. Por ejemplo, el trabajo de Patel et. al. \cite{patel_image_2020}, desarrolla un sistema de videovigilancia doméstico y accionamiento remoto de cerraduras basado en una Raspberry Pi 3B+. 

El sistema utiliza un nodo local que captura únicamente fotografías, en lugar de video continuo, cuando se detecta presencia de movimiento por sensor infrarrojo o se pulsa el timbre. Las imágenes se envían a un \textit{bucket} de Amazon S3; allí, una función AWS Lambda entrega la imagen a Amazon Rekognition, almacena los vectores faciales en DynamoDB y notifica al usuario vía aplicación móvil y correo electrónico. Si la persona es reconocida, un disparador Lambda instruye a la Raspberry Pi para accionar el relé de la cerradura y mostrar un saludo personalizado en pantalla LCD. Este diseño traslada la pesada tarea de inferencia a la nube, reduce el ancho de banda (solo se suben fotografías instantáneas) y aprovecha los servicios gestionados de AWS para orquestar elasticidad, notificaciones y persistencia de eventos \cite{patel_image_2020}.

Otro ejemplo es el de Kanna et. al. \cite{kanna_smart_2021}, en el que se demuestra la viabilidad de un sistema inteligente de asistencia en campus que fusiona RFID y reconocimiento facial. Una Raspberry Pi 4B gestiona simultáneamente la lectura de etiquetas MFRC522 y la captura de 30 FPS con una cámara USB. Cada segundo se genera un fotograma compuesto que se envía a una colección de Amazon Rekognition, donde se comparan los rostros con los registrados, aplicando un umbral de similitud del 85\%. Cuando el UID RFID y la cara coinciden, la asistencia se marca automáticamente y se sincroniza en tiempo real con Firebase, permitiendo a administradores y estudiantes consultar registros desde una aplicación Android. La arquitectura aprovecha a Rekognition para la identificación fiable bajo iluminación y poses variables, mientras que Firebase simplifica el \textit{backend} de datos y las notificaciones, conservando en la Raspberry Pi solo el procesamiento ligero de captura y transmisión.

Ambos casos prácticos evidencian la estrategia de delegar las operaciones de visión por computador a un servicio gestionado, manteniendo en el dispositivo empotrado tareas de adquisición de datos y control de actuadores. La combinación de hardware de bajo costo (Raspberry Pi), Amazon Rekognition como motor de análisis centralizado y servicios auxiliares (S3, DynamoDB, Lambda, Firebase) permite construir soluciones robustas, escalables y de fácil mantenimiento, superando las limitaciones de cómputo, almacenamiento y actualización de firmware típicas de los sistemas embebidos tradicionales.
